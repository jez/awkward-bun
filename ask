#!/usr/bin/env python

from __future__ import print_function
import sys
import time
import codecs
from Queue import PriorityQueue

# this module should be imported before using any NLTK or Stanford Parser code,
# as it initializes these with their support folders.
import settings as s

import grammar_util as g
import util
from contractions import expand_contractions

import nltk
from nltk.tree import Tree
from nltk.parse import stanford as stanford_parse
from nltk.tag import stanford as stanford_tag
from pattern.en import conjugate


def pronounToNounPhrase(replacements):
    def fn(node):
        pos = node.label()
        if pos == 'PRP':
            return replacements
        elif pos == 'PRP$':
            return Tree('NP', replacements + [Tree('POS', ["'s"])])
    return fn

def disambiguateWith(sense, subject, replacements):
    if sense == 'PERSON':
        pred = g.is_heshehishers
    elif sense == 'IMPERSONAL':
        pred = g.is_itits
    else:
        return subject

    replacer = pronounToNounPhrase(replacements)
    result, replaced = g.replace_leftmost(subject, pred, replacer)
    return result


def try_make_binary_question(node, article_title, sense):
    node_new = g.filter_tree(node, lambda n: n.label() != 'PRN')
    if not g.is_simple_pred(node_new):
        node_no_prn = node

    subject = disambiguateWith(sense, g.get_subject(node_new), article_title)

    pred = g.get_predicate(node_new)

    verb_node = next(t for t in pred if g.is_verb(t))
    verb_idx = pred.index(verb_node)
    if g.is_leaf(verb_node):
        verb_str = ' '.join(verb_node)
        verb_inf = conjugate(verb_str, 'VB')
    else:
        g.log_error(node_new, "Thought verb was terminal, but it wasn't: %s" % `verb_node`)
        return None

    result_node = None
    extras = {'verb_inf': verb_inf}
    if len(filter(g.is_verb, pred)) == 1 and verb_inf != 'be':
        verb_pos = verb_node.label()
        new_pred = pred[:]
        new_pred[verb_idx] = Tree('VB', [verb_inf])
        result_node = Tree('ROOT', [Tree('SQ', [
                g.upcase(Tree(verb_pos, [conjugate('do', verb_pos)])),
                g.downcase(subject),
                ] +
                new_pred +
                [Tree('.', ['?'])]
            )])
    else:
        result_node = Tree('ROOT', [Tree('SQ', [
            g.upcase(verb_node),
            g.downcase(subject)
            ] +
            (pred[:verb_idx] + pred[verb_idx+1:]) +
            [Tree('.', ['?'])]
            )])

    return { 'node': result_node, 'extras': extras}

def rank_binary_question(sentence, question, extras):
    score = 0

    num_words = len(sentence.leaves())
    height = sentence.height()
    subject = g.get_subject(sentence)
    pred = g.get_predicate(sentence)

    if extras['verb_inf'] == 'be':
        score += 1

    # special case an incorrectly parsed sentence in Python (language):
    # "Does Python 3.0 change / to be ..." -> '/' becomes verb??
    if extras['verb_inf'] == '/':
        score -= 5

    if num_words <= 16:
        score += 1

    if num_words <= 10:
        score += 0.5

    if height <= 13:
        score += 0.5

    if height <= 10:
        score += 0.75

    if g.tree_any(subject, g.is_proper_noun):
        score += 1.25

    if g.tree_any(subject, g.is_prp):
        score -= 0.5

    if g.tree_any(subject, g.is_definite_article):
        score -= 0.75

    return score


def process_sentence(sp, title_info, raw_sentence):
    result = {
            'total_count': 1,
            'simple_pred_count': 0,
            'fail_count': 0,
            'rank': 0,
            'sentence': '',
            'question': '',
    }

    article_title = title_info['article_title']
    article_sense = title_info['article_sense']

    # The parser gives back an iter(Tree).
    # TODO: Handle when the size of `parses` is not 1
    parses = sp.raw_parse(expand_contractions(raw_sentence))

    # get 0'th tree from iterator of parses
    tree = next(parses)
    result['sentence'] = tree

    if g.is_simple_pred(tree):
        result['simple_pred_count'] = 1

        util.log(tree)

        rc = try_make_binary_question(tree, article_title, article_sense)

        if rc is None:
            result['fail_count'] = 1
        else:
            question = rc['node']
            result['question'] = question
            extras = rc['extras']

            util.log(g.as_string(question))

            result['rank'] = rank_binary_question(tree, question, extras)

        util.log('-' * 80)

    return result


def process_title(sp, st, raw_title):
    title_parsed = next(sp.raw_parse(raw_title))
    title_tagged = st.tag(raw_title.split())

    filtered = g.filter_tree(title_parsed, lambda node: node.label() != 'PRN')
    article_title = g.unwrapUntilNP(filtered)

    result = {
        'article_title': article_title,
        'article_sense': None,
    }

    if all([tag == 'PERSON' for tok, tag in title_tagged]):
        result['article_sense'] = 'PERSON'
    else:
        result['article_sense'] = 'IMPERSONAL'

    return result


def main(article_name, nquestions):
    sp = stanford_parse.StanfordParser()
    st = stanford_tag.StanfordNERTagger(s.ENGLISH_TAGGER)

    with codecs.open(article_name, encoding='utf-8') as f:
        raw_title = f.readline()
        sentences = nltk.sent_tokenize(f.read())

    total_count = 0
    simple_pred_count = 0
    fail_count = 0
    bests = PriorityQueue()

    start_time = time.time()

    title_info = process_title(sp, st, raw_title)

    for raw_sentence in sentences:
        if len(raw_sentence) > 150:
            continue

        rc = process_sentence(sp, title_info, raw_sentence)

        total_count += rc['total_count']
        simple_pred_count += rc['simple_pred_count']
        fail_count += rc['fail_count']

        bests.put((rc['rank'], rc['question'], rc['sentence']))

        if bests.qsize() > nquestions:
            _ = bests.get()

        if time.time() - start_time > 4.9 * 60:
            # Save some time to output our answer before the timeout
            break


    util.log('\nSUMMARY:\n')
    util.log('Sentences:    %d' % total_count)
    util.log('Simple pred:  %d' % simple_pred_count)
    util.log('Failed:       %d' % fail_count)
    util.log()

    for score, question, sentence in bests.queue:
        util.log('[%0.2f] %s' % (score, g.as_string(question)))
        util.output(g.as_string(question))


if __name__ == '__main__':
    if len(sys.argv) != 3:
        print('usage: %s <article> <nquestions>' % sys.argv[0])
        sys.exit(1)

    article_name = sys.argv[1]
    nquestions = int(sys.argv[2])

    main(article_name, nquestions)
